{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spotify Charts Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "def line_refresher(printed_string, variables):\n",
    "    function_line = printed_string.format(*variables)\n",
    "    def line_refresher_function(*variable):\n",
    "        sys.stdout.write(\"\\r\" + function_line.format(*variable))\n",
    "        sys.stdout.flush()\n",
    "    return line_refresher_function\n",
    "\n",
    "# b = \"the man\"\n",
    "# a = line_refresher(\"Is '{}' working for {}?\", ['{}', b])\n",
    "# a(\"Elliott\")\n",
    "# sleep(2)\n",
    "# a(\"Frankie\")\n",
    "# sleep(2)\n",
    "# a(\"the Man\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log10, floor\n",
    "\n",
    "def sigfigs(number, sf):\n",
    "    return max(\n",
    "        round(number, sf - int(floor(log10(abs(number)))) - 1),\n",
    "        1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_timer(seconds, reset=False):\n",
    "    pass\n",
    "    # Checks if the number of seconds have passed since the last check. If they have, or reset=True, reset the timer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(lst, n):\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i : i+n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "import os\n",
    "\n",
    "log_folder = \"data/logs\"\n",
    "\n",
    "def mp_download_files(chart_type, country_list, date_list, queue, name):\n",
    "    total_count = len(country_list) * len(date_list)\n",
    "    current_count = 0\n",
    "    error_count = 0\n",
    "    queue.put( (name, total_count, current_count, error_count) )\n",
    "    \n",
    "    output_base = os.path.join(\"data\", chart_type)\n",
    "    \n",
    "    for country_abbrev, country_name in country_list:\n",
    "        \n",
    "        output_folder = os.path.join(output_base, country_abbrev)\n",
    "        if not os.path.isdir(output_folder):\n",
    "            os.mkdir(output_folder)\n",
    "            \n",
    "        for date in date_list:\n",
    "            \n",
    "            # Add updated information to the queue every ten files\n",
    "            if file_count % 50 == 0:\n",
    "                queue.put( (name, total_count, current_count, error_count) )\n",
    "            \n",
    "            # Get the data\n",
    "            try:\n",
    "                # Attempt to get the data\n",
    "                r_temp = requests.get(\"https://spotifycharts.com/{}/{}/daily/{}/download\".format(\n",
    "                    chart_type, country_abbrev, date))\n",
    "                assert r_temp\n",
    "                \n",
    "                output_text = \"# {} chart for {} on {}\\n#\".format(chart_type, country_name, date) + r_temp.text\n",
    "                \n",
    "                with open(\"data/{}/{}_{}_{}.csv\".format(chart_type, chart_type, country_abbrev, date), \"wb\") as f:\n",
    "                    f.write(output_text.encode('utf-8'))\n",
    "            \n",
    "            except Exception as e:\n",
    "                log_text = \"EXCEPTION: {}\".format(e)\n",
    "                log_name = \"data/logs/{}_{}_{}.txt\".format(chart_type, country_abbrev, date)\n",
    "                with open(log_name, \"w\") as log:\n",
    "                    log.write(log_text)\n",
    "                error_count += 1\n",
    "            \n",
    "            current_count += 1\n",
    "    \n",
    "    queue.put( (name, total_count, current_count, error_count) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regional Daily Top 200 Songs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get a list of all possible countries and dates to scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of all possible countries and dates to scrape\n",
    "r_regional = requests.get(\"https://spotifycharts.com/regional/\")\n",
    "soup = bs(r_regional.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the output to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Download the list of available countries\n",
    "country_div = soup.find(\"div\", attrs={\"class\":\"responsive-select\",\"data-type\":\"country\"})\n",
    "country_list = [(li.attrs['data-value'], li.text) for li in country_div.find_all(\"li\")]\n",
    "json.dump(country_list, open(\"data/regional_countries.txt\", \"w\"))\n",
    "          \n",
    "# Download list of available dates\n",
    "date_div = soup.find(\"div\", attrs={\"class\":\"responsive-select\", \"data-type\":\"date\"})\n",
    "date_list = [li.attrs['data-value'] for li in date_div.find_all(\"li\")]\n",
    "json.dump(date_list, open(\"data/regional_dates.txt\", \"w\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run parallel processes to download the data\n",
    "\n",
    "The processes must be entirely imported from another file due to the way that `multiprocessing` interacts with the Interactive Environment of Jupyter Notebooks.\n",
    "For more details, see:\n",
    "\n",
    "https://stackoverflow.com/questions/23641475/multiprocessing-working-in-python-but-not-in-ipython/23641560#23641560\n",
    "\n",
    "https://stackoverflow.com/questions/20222534/python-multiprocessing-on-windows-if-name-main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'process_0: 6912 / 6912 files downloaded (1152 errors).'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'process_1: 6912 / 6912 files downloaded (654 errors).'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'process_2: 6912 / 6912 files downloaded (956 errors).'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'process_3: 6912 / 6912 files downloaded (245 errors).'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'process_4: 6912 / 6912 files downloaded (0 errors).'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'process_5: 6912 / 6912 files downloaded (1217 errors).'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'process_6: 6912 / 6912 files downloaded (2275 errors).'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'process_7: 6912 / 6912 files downloaded (1604 errors).'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'process_8: 6912 / 6912 files downloaded (0 errors).'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'process_9: 6912 / 6912 files downloaded (437 errors).'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'process_10: 6912 / 6912 files downloaded (1180 errors).'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Download complete!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from IPython.display import display, clear_output\n",
    "import multiprocessing as mp\n",
    "import download_workers\n",
    "\n",
    "queue = mp.Queue()\n",
    "\n",
    "country_chunks = list(chunks(country_list, 6))\n",
    "\n",
    "processes = [mp.Process(target=download_workers.mp_download_files,\n",
    "                        args=('regional', country_chunks[i], date_list, queue, i)) for \\\n",
    "                        i in range(len(country_chunks))]\n",
    "\n",
    "print(\"Processes Created.\")\n",
    "\n",
    "active_processes = [True for i in range(len(processes))]\n",
    "process_text = [\"process_{}: starting...\".format(i) for i in range(len(processes))]\n",
    "\n",
    "print(\"Activating processes...\")\n",
    "\n",
    "for p in processes:\n",
    "    p.start()\n",
    "\n",
    "for text in process_text:\n",
    "    display(text)\n",
    "    \n",
    "check_ticker = 0\n",
    "while any(active_processes):\n",
    "    text_changed = False\n",
    "    while not queue.empty():\n",
    "        text_changed = True\n",
    "        (p_name, total_count, current_count, error_count) = queue.get()\n",
    "        if current_count == total_count:\n",
    "            processes[p_name].join()\n",
    "            active_processes[p_name] = False\n",
    "        process_text[p_name] = \"process_{}: {} / {} files downloaded ({} errors).\".format(\n",
    "            p_name, current_count, total_count, error_count)\n",
    "    \n",
    "    if text_changed:\n",
    "        clear_output(True)\n",
    "        for text in process_text:\n",
    "            display(text)\n",
    "    \n",
    "#     check_ticker += 1\n",
    "#     display(check_ticker)\n",
    "    time.sleep(1)\n",
    "        \n",
    "print(\"\\nDownload complete!\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in processes:\n",
    "    p.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Downloading files through parallel processes\n",
    "# import time\n",
    "# from IPython.display import display, clear_output\n",
    "\n",
    "# output_queue = mp.Queue()\n",
    "\n",
    "# print(\"Creating processes...\")\n",
    "\n",
    "# country_chunks = list(chunks(country_list, 3))\n",
    "\n",
    "# processes = [mp.Process(target=mp_download_files, args=('regional', country_chunks[i], date_list, output_queue, i)) for \\\n",
    "#                 i in range(len(country_chunks))]\n",
    "\n",
    "# print(\"Processes created.\")\n",
    "\n",
    "# active_processes = [True for i in range(len(processes))]\n",
    "\n",
    "# process_text = [\"process_{}: starting...\".format(i) for i in range(len(processes))]\n",
    "\n",
    "# for text in process_text:\n",
    "#     display(text)\n",
    "# # display(\"\\n\".join(process_text))\n",
    "\n",
    "# print(\"Activating processes...\")\n",
    "\n",
    "# for p in processes:\n",
    "#     p.start()\n",
    "\n",
    "# while any(active_processes):\n",
    "#     text_changed = False\n",
    "#     while not output_queue.empty():\n",
    "#         text_changed = True\n",
    "#         (p_name, total_count, current_count, error_count) = output.get()\n",
    "#         if current_count == total_count:\n",
    "#             processes[p_name].join()\n",
    "#             active_processes[p_name] = False\n",
    "#             process_text[p_name] = \"process_{}: {} / {} files downloaded ({} errors).\".format(\n",
    "#                 p_name, current_count, total_count, error_count)\n",
    "    \n",
    "#     if text_changed:\n",
    "#         clear_output(True)\n",
    "#         display(\"\\n\".join(process_text))\n",
    "        \n",
    "# print(\"\\nDownload complete!\")\n",
    "        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as dtimer\n",
    "\n",
    "total_files = len(date_list) * len(country_list)\n",
    "base_increment = sigfigs(total_files/100, 1)\n",
    "\n",
    "update_line = line_refresher(\"{} / {} files downloaded...\", ['{}', total_files])\n",
    "\n",
    "file_count = 0\n",
    "next_file_marker = base_increment\n",
    "last_refresh_time = dtimer()\n",
    "update_line(file_count)\n",
    "start_time = last_refresh_time\n",
    "\n",
    "for country_pair in country_list:\n",
    "    for date in date_list:\n",
    "        \n",
    "        if file_count == 10:\n",
    "            print(\"Predicted time: \", total_files/10 * (dtimer() - start_time))\n",
    "        \n",
    "        if file_count >= next_file_marker or dtimer() - 30 > last_refresh_time:\n",
    "            last_refresh_time = dtimer()\n",
    "            if file_count >= next_file_marker:\n",
    "                next_file_marker += base_increment\n",
    "            update_line(file_count)\n",
    "        \n",
    "        country_abbrev = country_pair[0]\n",
    "        country_name = country_pair[1]\n",
    "        r_temp = requests.get(\"https://spotifycharts.com/regional/{}/daily/{}/download\".format(country_abbrev, date))\n",
    "        if r_temp:\n",
    "            with open(\"data/top-200_{}_{}.csv\".format(country_abbrev, date), \"wb\") as f:\n",
    "                f.write(\"# Top 200 list for {} on {}\\n#\".format(country_name, date).encode('utf-8'))\n",
    "                f.write(r_temp.text.encode('utf-8'))\n",
    "        else:\n",
    "            print(\"ERROR: Request failed with code '{}' - {} ({}), {}\".format(\n",
    "                r_temp.status_code, country_name, country_abbrev, date))\n",
    "\n",
    "        file_count += 1\n",
    "print(\"\\nComplete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regional Daily Viral 50 Songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of all possible countries and dates to scrape\n",
    "r_regional = requests.get(\"https://spotifycharts.com/viral/\")\n",
    "soup = bs(r_regional.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_country_div = soup.find(\"div\", attrs={\"class\":\"responsive-select\",\"data-type\":\"country\"})\n",
    "v_country_list = [(li.attrs['data-value'], li.text) for li in v_country_div.find_all(\"li\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_date_div = soup.find(\"div\", attrs={\"class\":\"responsive-select\", \"data-type\":\"date\"})\n",
    "v_date_list = [li.attrs['data-value'] for li in v_date_div.find_all(\"li\")]\n",
    "print(\"Time span of charts (years):\", len(v_date_list)/365)\n",
    "v_sorted_date_list = sorted(v_date_list)\n",
    "print(\"From {} to {}\".format(v_sorted_date_list[0], v_sorted_date_list[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as dtimer\n",
    "\n",
    "v_total_files = len(v_date_list) * len(v_country_list)\n",
    "base_increment = sigfigs(v_total_files/100, 1)\n",
    "\n",
    "update_line = line_refresher(\"{} / {} files downloaded...\", ['{}', v_total_files])\n",
    "\n",
    "file_count = 0\n",
    "next_file_marker = base_increment\n",
    "last_refresh_time = dtimer()\n",
    "update_line(file_count)\n",
    "\n",
    "for country_pair in v_country_list:\n",
    "    for date in v_date_list:\n",
    "        \n",
    "        if file_count >= next_file_marker or dtimer() - 30 > last_refresh_time:\n",
    "            last_refresh_time = dtimer()\n",
    "            if file_count >= next_file_marker:\n",
    "                next_file_marker += base_increment\n",
    "            update_line(file_count)\n",
    "        \n",
    "        country_abbrev = country_pair[0]\n",
    "        country_name = country_pair[1]\n",
    "        r_temp = requests.get(\"https://spotifycharts.com/viral/{}/daily/{}/download\".format(country_abbrev, date))\n",
    "        if r_temp:\n",
    "            with open(\"data/viral-50_{}_{}.csv\".format(country_abbrev, date), \"wb\") as f:\n",
    "                f.write(\"# Top 200 list for {} on {}\\n#\".format(country_name, date).encode('utf-8'))\n",
    "                f.write(r_temp.text.encode('utf-8'))\n",
    "        else:\n",
    "            print(\"ERROR: Request failed with code '{}' - {} ({}), {}\".format(\n",
    "                r_temp.status_code, country_name, country_abbrev, date))\n",
    "\n",
    "        file_count += 1\n",
    "print(\"\\nComplete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "test_df = pd.read_csv(\"data/top-200_global_2020-02-29.csv\", comment='#', encoding=\"latin-1\")\n",
    "test_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
